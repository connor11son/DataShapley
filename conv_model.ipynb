{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Connor\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\compat\\v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import glob\n",
    "import sys\n",
    "import time\n",
    "import numpy as np\n",
    "from Shapley import ShapNN\n",
    "from Shapley import CShapNN\n",
    "from DShap import DShap\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from shap_utils import *\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "%matplotlib inline\n",
    "MEM_DIR = './'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load In Images\n",
    "\n",
    "In my cwd, I have two files: one containing cat pictures and another containing \n",
    "dog pictures. Here I load them into a a list of arrays so that I can create my train/test sets later. I also create a list of labels such that each time I load a cat image into my list of arrays, the corresponding index in the \"labels\" list will have a 0 (and a 1 for each dog image). I will just load in 25 from each class for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = []\n",
    "\n",
    "labels = []\n",
    "\n",
    "for file in os.listdir('cat_train'):\n",
    "        \n",
    "        logits.append(img_to_array(load_img('cat_train\\\\'+file, target_size = (227,227))))\n",
    "        \n",
    "        labels.append(0)\n",
    "        \n",
    "        if len(labels) == 25:\n",
    "            break\n",
    " \n",
    "for file in os.listdir('dog_train'):\n",
    "    \n",
    "    logits.append(img_to_array(load_img('dog_train\\\\'+file, target_size = (227,227))))\n",
    "    \n",
    "    labels.append(1)\n",
    "    \n",
    "    if len(labels) == 50:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create train/test set\n",
    "\n",
    "Here I create an array of all my image arrays (and labels), and then shuffle the arrays so that they are in random order. Then I create a test set of the last 10 arrays of my train set, and then delete them from my train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(logits)\n",
    "y = np.array(labels)\n",
    "\n",
    "X, y = shuffle(X, y, random_state=0)\n",
    "\n",
    "X_test = (X[40:50])\n",
    "y_test = (y[40:50])\n",
    "\n",
    "X = (np.delete(X, axis=0, obj = slice(40,50)))\n",
    "y = (np.delete(y, axis= 0, obj = slice(40,50)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training images: (40, 227, 227, 3)   Shape of training labels: (40,)\n",
      "Shape of testing images: (10, 227, 227, 3)   Shape of testing labels: (10,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of training images:\", X.shape, \"  Shape of training labels:\", y.shape)\n",
    "\n",
    "print(\"Shape of testing images:\", X_test.shape, \"  Shape of testing labels:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Model Architecture\n",
    "\n",
    "The model type \"conv\" loops through the convolution layers first, then goes to the dense layers. Here is what each argument means:\n",
    "\n",
    "kernel_sizes: List of integers. Each integer represents the side length of a square filter for a convolution layer. For example, if my kernel_sizes is [3,4], then the first convolution layer will have a filter of size (3,3,number of channels of input image). The second convolution layer will have a filter of size (4,4,number of filters in first layer).\n",
    "\n",
    "channels: List of integers. Each integer represents the number of filters in each layer. For example, if my channels is [10,20] and my kernel_sizes is [3,4], the first convolution layer will have 10 filters of size (3,3,number of channels of input image). The second convolution layer will have 20 filters of size (4,4,10). You do not need to make channels[0] equal to number of channels in your images, as that is already done for you.\n",
    "\n",
    "hidden_units: List of integers. Each integer represents the number of nodes in each dense layer (which all occur after the final conv layer). The final dense layer is built for you already, so you do not have to worry about making hidden_units[-1] equal to the number of classes you have - it can be whatever you want.\n",
    "\n",
    "Everything else should work as it does with other models. A couple things to note: There is something inside the library built to handle images with size (number of images, height, width), meaning there is 1 channel. However, I could not get it to work yet. Also, if the directory you are saving stuff to already exists, make sure to set \"overwrite\" to True. If you don't, it makes dataset for you and can cause some errors (I'm sure it has a purpose, just do not know how it works).\n",
    "\n",
    "Also, gshap is not built to run for convolutional networks (even though it would be way faster than tmc shap). So if you run with g_run set to True, it will be a fully dense network with architecture of hidden_units. Not sure how it resizes the images for that to work, but it does it somehow.\n",
    "\n",
    "Also note that this algorithm is very slow. I am running this shallow network on an RTX 2080 and it takes a few hours to converge on values for 50 images. If gshap every gets support for model type 'conv', it will run much faster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem, model = 'classification', 'conv'\n",
    "kernel_sizes = [3,3]\n",
    "channels = [16,24]\n",
    "hidden_units = [128,64]\n",
    "num_test = 10\n",
    "directory = './temp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dshap = DShap(X, y, X_test, y_test, num_test, model_family=model, metric='accuracy',\n",
    "              directory=directory, problem=problem, seed=1, hidden_units = hidden_units, \n",
    "              channels = channels, kernel_sizes = kernel_sizes, batch_size = 32, overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LOO score calculations!\n",
      "WARNING:tensorflow:From C:\\Users\\Connor\\Desktop\\DS\\DataShapley-master\\Shapley.py:304: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "LOO values calculated!\n"
     ]
    }
   ],
   "source": [
    "dshap.run(100, 0.1, g_run = False, loo_run = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dshap.merge_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "convergence_plots(dshap.marginals_tmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dshap.performance_plots([dshap.vals_tmc, dshap.vals_loo], num_plot_markers=20,\n",
    "                       sources=dshap.sources)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
